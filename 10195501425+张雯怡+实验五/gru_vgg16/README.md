# 任务介绍

基于文本图像的多模态图像识别

## 运行环境
见requirements.txt

## 训练数据预处理

对train数据进行shuffle后按8:2比例切分成训练集和验证集，文本和图片分别以不同格式处理：
文本部分处理成`content + \t + label`的txt文件，
图片部分处理成`index + \t + label`的txt文件

> cd data
> python data_process

## 模型介绍

本实验采用基于word2vec+GRU+VGG16的多模态模型，
对于文本部分采用glove预训练的英文word2vec词向量加上biGRU模型进行特征抽取，
对于图像部分采用vgg16模型进行特征抽取，将两种模态特征进行concat操作后输入MLP进行结果分类

## 训练和预测
超参数在`utils/config.py`处设置，训练结束后效果最好的模型保存在`saved_dict`文件夹下，生成的预测文件在`data/实验五数据/test_with_label.txt`路径下
> python run.py 

### 模型保存
最好模型保存在saved_dict文件夹，训练过程和模型构造在log文件夹

## 消融实验和结果说明

对于该分类任务，该多模态模型效果并不好。
但是在后续消融实验中，采用word2vector+GRU（或LSTM）对纯文本进行分类，得到的结果却更加糟糕！
而采用VGG16对纯图像进行分类，效果是更好的。
查看并分析文本数据后可知，该数据集文本存在两个问题使其不规整：一方面它有多种语言、乱码，另一方面大多都并非完整的句子，文本数据质量较差，反而对模型起到了负面效果，所以后续我直接暴力的把文本特征压缩到长度为一的张量进行拼接，尽量减少脏数据的影响。
图像方面由于数据分布极不均匀，而且neutral标签数据过少，导致模型很难学习到相关分类特征，分类效果也比较差。

